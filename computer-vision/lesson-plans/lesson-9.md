# Lesson 9

## Overview (Teacher)

**How might bias affect users who engage with computer vision applications?**

Summary of what is in this lesson (2-3 sentences). How does this fit into the big picture \[optional] (2-3 sentences)?

## Overview (Students)

A student-friendly version of the text above. Speak directly to the students.



{% tabs %}
{% tab title="Slides" %}
{% embed url="https://docs.google.com/presentation/d/1mk85wn2sT6M5R7STRXHGL7q51bG3CZYW5XR5-N5YjEE/edit?usp=sharing" %}
{% endtab %}

{% tab title="Standards" %}
| CSTA: 3A-AP-16            | Design and iteratively develop computational artifacts for practical intent, personal expression, or to address a societal issue by using events to initiate instructions. |
| ------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| CSTA: 3A-AP-13            | Create prototypes that use algorithms to solve computational problems by leveraging prior student knowledge and personal interests.                                        |
| <p>AI4K12:<br>3-A-iii</p> | Training a model - Use either a supervised or unsupervised learning algorithm to train a model on real world data, then evaluate the results.                              |
{% endtab %}

{% tab title="Objectives" %}
* Explore how visual data is used within a machine learning algorithm to train and create a model
* Train, validate, and test basic AI classification systems in computer vision
* Create and evaluate prototypes that solve problems using computer vision
{% endtab %}

{% tab title="Preparation" %}
* Blank white paper will be needed for the warm-up. You can cut it into quarters in advance.
* Students should have the items needed to train their model (webcam / images / video / microphone, etc.)
* Verify that students have access to the [Teachable Machine website](http://teachablemachine.withgoogle.com) in order to train their models.
{% endtab %}

{% tab title="Links" %}
For the teachers

* [Model-Making Machine](https://docs.google.com/presentation/d/1mk85wn2sT6M5R7STRXHGL7q51bG3CZYW5XR5-N5YjEE/edit?usp=sharing)- Slides
* [Teachable Machine 2.0](https://youtu.be/T2qQGqZxkD0?feature=shared)- Video
* [Object Cards](https://docs.google.com/presentation/d/1vq99wxIkEBMhOt9h3QzDF35A6WWson3U3s7\_suZXoFQ/edit?usp=sharing) - Resources

For the students

* [Teachable Machine 2.0](https://youtu.be/T2qQGqZxkD0?feature=shared)- Video
* [Teachable Machine](http://teachablemachine.withgoogle.com) - Website
{% endtab %}

{% tab title="Vocabulary" %}
model - programs that detect specific patterns using a collection of data sets
{% endtab %}
{% endtabs %}

‚òëÔ∏è **Do This:** Instructions for the teacher to do

üí¨ **Discuss:** discussion prompt

üí° **Discussion Goal:** what the teacher should be listening for in the discussion

üíª **Transition:** where students should be transitioning to

‚úèÔ∏è **Vocabulary:** new term being introduced

üé• **Video:** Show the video "Video Title"

üü° Click the animation

üìÑ **Distribute:** Give each student/pair of students a copy of the Activity Title activity guide.

> üéôÔ∏è **Say:** thing for the teacher to say

üîÅ **Circulate:** what the teacher should be looking out for while walking the classroom

Teaching Tip: Title teaching tip content

Assessment Opportunity: Formative Assessment assessment opportunity content

> üéôÔ∏è **Say:** To begin with today, we are going to play a little bingo game. But rather than the classic version with letters and numbers, you will be given a Bingo card with a variety of statements. Within a set time limit, your job is to circulate around the classroom, talk with your classmates, and find people who agree that one of the statements describes something that they might think or do.

If there is a match, have them put their initials in the box. Once you have that classmate‚Äôs initials, move on to a different person‚Äì try not to have the same set of initials twice on your card.

Try not to overthink it; if the description feels generally true, then go ahead and initial it.

Once you have a horizontal, vertical, or diagonal line, call out ‚ÄúBingo!‚Äù

üìÑ **Distribute:** Bingo Cards.

üí¨ **Discuss:** The boxes on the Bingo card all described different scenarios, but was there any pattern or connection between them?

**Discussion Goal:** All of the descriptions read described a situation where some level of bias might have been an influencing factor. Bias is defined as having a tendency to prefer one‚Äôs own viewpoint / outlook towards a particular subject. The descriptions provided were all intended to be low risk and low impact forms of bias that are common for people to adopt without realizing that their decisions are being subtly biased.

> üéôÔ∏è **Say:** Just like we sometimes have subtle or hidden bias that can influence our decisions or actions, so, too, can datasets and computer vision applications also have bias. Today we are going to be looking at how that might manifest while using data to train a computer vision model and discuss ways that we might be able to remedy or reduce bias so that any model that we train has a higher probability of acting in the manner which we expect that it might.

‚úèÔ∏è **Vocabulary:** Bias - when a decision favors some things and deprioritizes or excludes others.

üñºÔ∏è Display: Lesson Objectives

üñºÔ∏è Display: Question of the Day

üé• **Video:** Training Data & Bias, Part 1 of 2

üí¨ **Discuss:** What are some ways that data might be collected for training models?

**Discussion Goal:** The video references a few examples‚Äì pointing out that the Captcha images that are used to verify whether we are humans or bots on websites are often used to crowdsource large datasets, usually connected to an image-related task. It also introduces the idea that video streaming services collect user preference data, and uses this information, along with the preferences of like-minded users, to generate recommendations.

Extension: Encourage students to think of some examples that exist outside of those mentioned in the video. If they cannot think of anything explicitly, you can prompt them to imagine a way to collect data from users. For example: What data do users give freely to apps like social media? How can your shopping patterns in an online store best used?

> üéôÔ∏è **Say:** One thing to keep in mind is that the less intrusive the data-collection process is for people, the more likely they are to participate in it, and to give accurate information.

üé• **Video:** Training Data & Bias, Part 2 of 2

> üéôÔ∏è **Say:** This video mentions one potential example of bias that exists in data, but let‚Äôs dig a little deeper and see if we can think of some more.

üí¨ **Discuss:** What are some other examples of bias in data that might exist in one of these sources: Facial recognition Voice recognition systems Social Media feeds

**Discussion Goal:** The video walks the students through an example of how medical imaging data that only uses x-rays from men might be biased and unreliable when it comes to making diagnoses on women‚Äôs x-rays. Here are some other examples that students might come up given the scenarios above: Facial recognition software - if models are trained on a variety of different ethic groups, then it might not work as intended Voice recognition systems - might be biased around certain types of accents over others Social media feeds - might only show information, groups, and stories based on what the algorithm judges as most likely to engage the user

> üéôÔ∏è **Say:** Let‚Äôs examine a hypothetical usage of computer vision to solve a problem that may be of interest to dog lovers the world over.

‚òëÔ∏è **Do This:** Have a student volunteer read the Auto-Doggie Door scenario

> üéôÔ∏è **Say:** We are going to revisit Mediapipe‚Äôs Object Detection model in order to see how well it might accomplish the task of identifying dogs for the Auto-Doggie Door.

‚òëÔ∏è **Do This:** Have students navigate to Mediapipe‚Äôs Object Detecton site.

> üéôÔ∏è **Say:** There is another series of images for you to download, and they are located within the Dogs resource folder. There are three different images for you to test.

‚òëÔ∏è **Do This:** Have students download the images from the Dogs folder (3) in order to test them.

> üéôÔ∏è **Say:** Upload the images one-by-one and examine the results of the object detection algorithm. Remember that you can adjust max results and score threshold to change the output of your results. You can also try changing the model / inference type that is being used within the model. If you have extra time at the end of the exploration, see if you can find your own image of a dog and upload it.

As you explore these images, remember the original premise of the scenario: we are building an Auto-Dog Door that will unlock when the camera built into the door recognizes a dog and stay locked if it doesn‚Äôt recognize a dog. Therefore, you should pay close attention to the confidence score that is related to the dog images that you are uploading into the model.

‚òëÔ∏è **Do This:** Have students explore these images. Should they have extra time, encourage them to test more and varied images to see what the output might be. They can find additional options searching an image search tool that is available on your campus (Google Images / Pexels / Pixabay / Flickr)

üîÅ **Circulate:** Assist students who are having difficulties with finding / uploading images. Point out the various settings that they can adjust while on the model and encourage them to try different combinations.

üí¨ **Discuss:** What were your results? Which dogs would this model let in or locked out? Discuss as a small group first, and then bring to a whole class discussion.

üí° **Discussion Goal:** Students should note which images yield high or low confidence scores. They should share their findings about the model's accuracy in identifying different dogs and any potential patterns or biases in its decisions. Students may also bring up that they notice certain types of dogs (breed, size, face shape, color etc.) were detected less often, which could be an opportunity to reinforce the concept of bias.

üü° Click the animation

üí¨ **Discuss:** How might we mitigate some of the bias that we witnessed? Whole class discussion

üí° **Discussion Goal:** Since this is the Object Detection model, it was trained using the COCOs image dataset. That might seem to suggest that the image dataset is not robust enough to account for the variety of dogs that might need to be identified. Adding more training images of different breeds, sizes, colors, face shapes, etc. could go a long way towards alleviating low confidence scores that certain images received.

> üéôÔ∏è **Say:** Today, we will be sharing the results of our design work thus far and getting feedback from our classmates about it. These checkpoint moments in the process of creating a project are important to learn about how you might continually iterate on your project to make it the best version possible.

‚òëÔ∏è **Do This:** Have students work with their group to complete the ‚ÄúOur Idea Outline‚Äù portion of the Design Document. This template will allow classmates (and you, the teacher!) to see an overview of the major strokes of the project at a glance: Who is the community that we are focusing on? What is the problem statement? What is the proposed solution using computer vision? What data might you need to gather to make your solution viable? What potential bias might exist in the data that you seek to collect?

üîÅ **Circulate:** Encourage students to use their pre-existing work to fill out this outline.

> üéôÔ∏è **Say:** Please place your ‚ÄúIdea Outline‚Äù document out so that other members of the class can circulate around and read it. You will be giving feedback to other groups using sticky notes. Don‚Äôt forget to bring something to write on, like a binder, book, or composition notebook.

‚òëÔ∏è **Do This:** Students will circulate around the room and give general feedback as to the high level direction of other groups‚Äô projects. Instruct them to use one sticky note per idea that they share so that it becomes easier to sort and parse through the feedback.

üîÅ **Circulate:** As the teacher, it would be helpful to model the process along with your students. Grab a stack of sticky notes and make comments on projects as well.

Teaching Tip: There are going to be two rounds of feedback in this activity. If you have multiple colors of sticky notes available for students, it would be a great idea to color-code the type of feedback that students are providing. For example, students can put things that they notice on yellow sticky notes, while posing their wonders / questions on blue sticky notes. This will help differentiate the types of feedback that different projects are receiving. Halfway through the activity, you can instruct students to pay attention to the predominant type of feedback that projects are receiving and to begin to provide the other type in order to achieve better balance.

A gallery walk is almost always more impactful and interesting if you treat the object of analysis like an actual piece of art in a gallery. This can be as simple as using tape and hanging the Idea Outlines on the wall, so that students can look at them in that fashion. If you have a quiet hallway nearby, you could also consider taking the activity outside of the classroom for more novelty and impact. At that point, it is highly recommended that it become a silent activity‚Äì all ‚Äútalking‚Äù is done through the sticky notes!

‚òëÔ∏è **Do This:** Students will make another pass at projects, except this time they will be focusing on identifying possible sources of bias that might exist in student proposals. They can also provide suggestions for how to mitigate that bias.

üîÅ **Circulate:** Again, engage with student projects and provide important checkpoint feedback for student groups.

Teaching Tip If you have a third color of sticky notes available, this activity would benefit from being differentiated by color as well. If you only have two colors of sticky notes available, consider just color-coding the feedback by round.

Assessment Opportunity: Formative As you make your way around the room to examine the different Idea Outlines, this would be a good time to see if students recognized the need for diverse and representative sources of data based on what sources they mention need to be collected.

> üéôÔ∏è **Say:** You‚Äôve come up with some impressive brainstorms regarding how you might address the problem statement that your group identified. Now that you have gotten some feedback from members of the class surrounding your design, our next steps will involve making some decisions about what solutions to focus on, and to begin to create a prototype that demonstrates a portion of our solution. That means that we are getting ready to transition from the Ideating phase of the Design Thinking Process into the Prototyping phase.

üéôÔ∏è Remarks: In the next class session, please come prepared with any media that you might need to train a sample model for your computer vision application. This can take the form of physical objects, images, video, sounds, music, etc. The more data that you bring, the better the model will likely perform. If the model does not perform as well as you thought it might, there will be opportunities during upcoming project time when you can make adjustments and tweaks to your model.

üí¨ **Discuss:** What physical objects, images, video, or other artifacts are you going to bring to class next to help train your model?

üí° **Discussion Goal:** This is a good time to make sure that students are clear that they will need to be responsible for bringing training data for their model in the next class period.

For example, if a student is making proposing an application that would help zookeepers know how many bananas a gorilla has eaten on a given day, then they would need to bring in a banana to train their model with‚Äì likely one that is undisturbed, and one that has been eaten and just the peel remains. Using this object, students could train a model to recognize both forms of banana, and could then use this model as a part of their application.

üñºÔ∏è Display: Lesson Objectives

üñºÔ∏è Display: Question of the Day

üñºÔ∏è Display: Key vocabulary
