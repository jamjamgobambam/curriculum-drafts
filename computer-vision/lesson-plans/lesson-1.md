<html><body><h1>lesson-1</h1><p>slides and notes (delete me)</p><table><tr><td>Slide</td><td>Lesson Guide</td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_0.png"></td><td>ğŸ’¬ <strong>Discuss:</strong><br /><br />ğŸ™ï¸ <strong>Say:</strong><br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_1.png"></td><td>Warm Up<br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_2.png"></td><td>ğŸ™ï¸ <strong>Say:</strong> In this comic, Calvin and Hobbes are playing Scrabble - a game where you score points based on the words you can create with random letters. On the next screen, you will see a list of â€œwordsâ€. Decide which ones are truly words like you can play in Scrabble and which are not.<br /><br />Teaching Tip: Classroom Prep<br />Before beginning this warmup, consider how you will manage the discussion on the next slide where students are sorting terms into â€œwordsâ€ or â€œnot wordsâ€. Consider having two sheets of poster paper that you can write on as the class sorts, or consider making a table on a whiteboard and writing the results there. You could also consider presenting these slides in â€œeditâ€ mode so you can move the text boxes around on the screen, but make sure you are able to reset the choices between class periods if you teach this lesson to multiple classes in the same day.<br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_3.png"></td><td>ğŸ’¬ <strong>Discuss:</strong> Have students discuss in groups before sharing out as a full class. Instead of going line-by-line through these words, ask students which decisions they are â€œmost confidentâ€ about and sharing their classification for those words first. Using this strategy, students will likely sort â€œ1) bananaâ€ and â€œ6) shirtâ€ as words, and â€œ2) aka7sj23kswâ€ and â€œ7) @&!*@^#â€ as not words. The remaining words are deliberately chosen to motivate certain discussions and create moments of cognitive dissonance and curiosity, hopefully allowing students to lead the discussion by asking questions or respectfully challenging ideas. Let students know they will likely change their minds as the discussion continues and thatâ€™s okay, and allowing students to state their confidence level for their initial thoughts can make them more comfortable speaking up since it feels less â€œhigh-stakesâ€. Be prepared to address the following situations in this discussion:<br /><br />3) cherimoya is a fruit common to South America, but may not be a common fruit your students have heard of. Itâ€™s possible many students may say â€œthis isnâ€™t a wordâ€, but one or two students may speak up because theyâ€™re familiar with this fruit. Be sure to elevate those voices and highlight how our own knowledge is sometimes limited by lack of exposure to different words or phrases. Or, if no one raises this point, be sure to point this out to students explicitly such as showing them the Wikipedia page. In either case, make sure cherimoya is classified as a â€œwordâ€ before leaving the discussion<br />8) ullaakkut and 10) yÃ¡'Ã¡t'Ã©Ã©h are both words in other languages - ullaakkut means hello in Inuktitut, a language spoken by Inuit peoples in Canada and Greenland; and yÃ¡'Ã¡t'Ã©Ã©h means â€œhelloâ€ in the Navajo / DinÃ© language. Similar to above, students may initially classify these as not words because they are unfamiliar with them, but it is important to surface the meaning and use of these words to students either with a quick google search or elevating the voice of a student in class who is already familiar with these words. As a result, make sure these terms donâ€™t end up in the â€œNot Wordsâ€ category by the end of the discussion.<br />4) wierd is a misspelling of either the word â€œweirdâ€ or the word â€œwiredâ€. Students may initially say that this is â€œnot a wordâ€, but another student or yourself should challenge them by pointing out that if this is typed into a device with autocorrect, it will automatically correct it to one of these other words. Even in this slide deck, the word has a red squiggly underline representing that the computer recognizes it as something, even if itâ€™s not a correctly spelled word. This may inspire the class to create a new category to represent this term - itâ€™s not a correctly spelled word, but itâ€™s also not a made-up word, so maybe thereâ€™s a new category for â€œmisspelled wordsâ€ or â€œimportant terms that arenâ€™t wordsâ€. Let students guide how they want to handle this situation, even if they decide not to make a new category and it remains in â€œnot wordâ€.<br />At some point, students who are more familiar with the Scrabble game may try to invoke the â€œrules of Scrabbleâ€ which restrict words in other languages, proper nouns, or abbreviations. From this perspective, words (8) and (10) above would be restricted, as would 5) Reykjavik (the capital of Iceland) and 9) ATM (since it is an abbreviation for Automatic Teller Machine). If this comes up, use this as an opportunity to question the effect that arbitrary rules have on what we consider valid language, since these are all definitely words that are used in society even if not officially allowed in Scrabble. You could consider creating new categories to represent these phrases, such as â€œStill words but not allowed in Scrabbleâ€ or â€œPart of language, but not allowed in Scrabbleâ€. Or, the class could decide these belong in the Words category, regardless of what Scrabble thinks, and thatâ€™s the end of the story.<br />ğŸ’¡ <strong>Discussion Goal:</strong> Ultimately, this is an exercise to surface that the way we identify words versus nonsense - much like Calvin and Hobbes in the comic panel - can be contextual to our lived experiences and influences what we consider important information versus random noise that can be ignored. Itâ€™s okay if the discussion ends without closure, so long as students have wrestled with how what they initially considered â€œwordsâ€ may have been expanded as they were exposed to new contexts in the discussion. However, be very intentional that the discussion ends with very few items in the â€œNot Wordsâ€ category, especially making sure ullaakkut and yÃ¡'Ã¡t'Ã©Ã©h are not in this category and are instead classified as either a Word or a new category the class has created.<br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_4.png"></td><td>ğŸ™ï¸ <strong>Say:</strong> Just from this warm-up, weâ€™ve already seen that it can be tricky trying to recognize â€œwordsâ€ from non-words. For a large-language model, those words are the inputs it uses to start generating itâ€™s response. Today, weâ€™re going to explore how a computer is able to recognize words used in language. This is the first step in understanding how a large-language model words - by looking at the inputs it uses!<br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_5.png"></td><td>Activity<br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_6.png"></td><td>ğŸ™ï¸ <strong>Say:</strong> When you use a large-language model, you start by giving it a prompt. In this example, weâ€™re asking it for a recipe for making chili.<br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_7.png"></td><td>ğŸ™ï¸ <strong>Say:</strong> As a first step, the model breaks apart this input into individual pieces.<br /><br />ğŸŸ¡ Click the animation<br /><br />ğŸ™ï¸ <strong>Say:</strong> Usually this is word by word<br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_8.png"></td><td>ğŸ™ï¸ <strong>Say:</strong> But sometimes itâ€™s even smaller, like when there is a root word or for punctuation. Technically, these are called tokens - theyâ€™re the smallest unit of data that a large-language model can represent.<br /><br />ğŸ™ï¸ <strong>Say:</strong> So then how does a large-language model learn how to recognize these words and tokens? And what words can it use when generating a response? Well - thatâ€™s exactly what weâ€™re going to learn about today!<br /><br />Teaching Tip: Viewing Tokens<br />If your school district allows access, OpenAI has a website that lets you preview how it interprets words and converts them into tokens: https://platform.openai.com/tokenizer. This can be a helpful visualization of how words are broken apart and interpreted by large language models. Consider demonstrating this for the class and typing in example sentences. Most words will likely be interpreted as single words, but compound words like â€œdecapodâ€, â€œanthologyâ€, â€œpretenseâ€, and â€œarachnophobiaâ€ are interpreted as two tokens instead of one. <br /><br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_9.png"></td><td>ğŸ“„ <strong>Distribute:</strong> Pass out the Training Data Activity Guide<br /><br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_10.png"></td><td>â˜‘ï¸ <strong>Do This:</strong> Read the overview of this document as a class. This text is also provided on the slide.<br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_11.png"></td><td>â˜‘ï¸ <strong>Do This:</strong> Have students complete each of the tables individually, listing examples of data sources in each location that could be used to help a large-language model represent different words. This requires identifying objects in these locations with text - literally any object - and imagining the words a language model could learn if it scanned the object.<br /><br />Since the first example is â€œThis Classroomâ€, you could do an example together as a class and point out any posters or books or anything with text. An easy example is the slide itself being projected, which would help a language model represent words like â€œDoâ€, â€œCompleteâ€, Includeâ€, etc. <br /><br />Itâ€™s not vital that students finish every aspect of this guide, since they will work in a group in the next section of this lesson. With that in mind, consider setting a timer to ensure students finish with enough time to move to the next part of the activity.<br /><br />ğŸ” <strong>Circulate:</strong> Monitor students as they complete this guide, noticing especially unique words or examples that can be useful to highlight in the next activity. If students are struggling, encourage them to visualize what it would look like if a computer sat in the middle of a space and scanned anything it saw - what words or symbols would it encounter?<br /><br />The next part of this activity requires making a poster - during this time, also be thinking about how you will distribute supplies to groups so they are ready to start right away with the next task.<br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_12.png"></td><td>â˜‘ï¸ <strong>Do This:</strong> Read the text on the slide to the class. Have students form groups of 3-4 people with a poster paper and markers. Each person should write the words from their activity guide onto the posters. They do not have to write the source they got it from. Groups should also find a way to emphasize words that are common across group members, such as writing it large or with special emphasis.<br /><br />Set a short timer for this activity. When a group is finished, their poster paper essentially represents a language model trained from a variety of sources curated by each student. These can be referred to in later parts of the unit as our understanding of language models evolves.<br /><br />ğŸ” <strong>Circulate:</strong> Ensure all students are able to participate and add their words to the poster. Emphasize and celebrate situations where a unique word appears on a poster that other models in the classroom likely wonâ€™t have.<br /><br />Teaching Tip: What Do Models â€œKnowâ€ At This Point?<br />The language being used in this lesson is very intentional, saying that models can â€œrepresentâ€ words as opposed to â€œknowâ€ or â€œunderstandâ€. Students may pick up on this and ask what the models really â€œknowâ€ or â€œunderstandâ€ at this point, or you may hear students saying the model â€œknows what this word meansâ€ which isnâ€™t quite correct. At this stage, all weâ€™re doing is building a â€œword bankâ€ that a model can recognize and eventually reproduce. But the model doesnâ€™t have any inherent understanding of the meaning of these words - this happens in later steps and later lessons. If we asked a model to respond to a prompt just with the training done today, it could generate any of the words students are putting on their posters, but the results would be random and nonsensical since it doesnâ€™t have any tools to help it make decisions about which words are best used in which situations. Nevertheless, this is a necessary step in understanding how a language model works - a model canâ€™t even begin to â€œunderstandâ€ a word if itâ€™s not even included in itâ€™s training data.<br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_13.png"></td><td>ğŸ™ï¸ <strong>Say:</strong> These are some great models weâ€™re building - such a wide variety of words theyâ€™re able to represent just from the sources we have close to us. But letâ€™s imagine we want to make sure weâ€™re providing enough data so it can eventually be used for certain tasks.<br /><br />â˜‘ï¸ <strong>Do This:</strong> In the following slides, a certain type of task will be presented. Students will discuss in groups what additional data sources would be necessary to make sure our model can represent the words needed for this task.<br /><br />Assessment Opportunity: Formative Assessment<br />The following prompts can be used as a formative assessment to see how members of the class understand the relationship between data sources used as input and the types of words a language model can represent from that source. You can get a pulse-check on this understanding by listening to how students respond as a class, or having them discuss in groups first and listen in on the conversations, or have students use the blank space on the back of their activity guide to write down their answers before responding. If you notice students are struggling to answer these questions, consider doing one or two as a class to model how students should think about this relationship between training data and what a model can represent.<br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_14.png"></td><td>ğŸ’¬ <strong>Discuss:</strong> What data sources should we use to make sure our model canâ€¦ Give a recipe and steps for making chili<br />ğŸ’¡ <strong>Discussion Goal:</strong> Possible answers can include:<br />Recipe books<br />Instruction manuals for kitchen appliances<br />History of chili cookoffs<br /><br />Optional: If any student posters seem to have any words relevant to this task, consider highlighting that poster as already having some relevant training data to this task.<br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_15.png"></td><td>ğŸ’¬ <strong>Discuss:</strong> What data sources should we use to make sure our model canâ€¦ Recommend places to hike in the southwest<br /><br />ğŸ’¡ <strong>Discussion Goal:</strong> Possible answers can include:<br />Travel books<br />Maps of Arizona<br />Hike Reviews<br /><br />Optional: If any student posters seem to have any words relevant to this task, consider highlighting that poster as already having some relevant training data to this task.<br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_16.png"></td><td>ğŸ’¬ <strong>Discuss:</strong> What data sources should we use to make sure our model canâ€¦ Help with math homework<br /><br />ğŸ’¡ <strong>Discussion Goal:</strong> Possible answers can include:<br />Math textbooks<br />Multiplication tables<br />How to be a good tutor books<br /><br />Optional: If any student posters seem to have any words relevant to this task, consider highlighting that poster as already having some relevant training data to this task.<br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_17.png"></td><td>ğŸ’¬ <strong>Discuss:</strong> What data sources should we use to make sure our model canâ€¦ Give relationship advice<br />ğŸ’¡ <strong>Discussion Goal:</strong> Possible answers can include:<br />Teen magazines (teen vogue / cosmo)<br />Self-help books<br />Fashion magazines<br /><br />Optional: If any student posters seem to have any words relevant to this task, consider highlighting that poster as already having some relevant training data to this task. <br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_18.png"></td><td>ğŸ’¬ <strong>Discuss:</strong> Even with all of this extra information and all of the data weâ€™ve sourced so far, there are still limits to what our models can doâ€¦ If we wanted our models to know the largest number of words possible, what do you think is a good data source to use?<br /><br />ğŸ’¡ <strong>Discussion Goal:</strong> This is intended to be a quick question with a single right answer: The internet. If students give answers other than this, continue to prompt them with â€œYah, but whatâ€™s even bigger than thatâ€¦â€ and work towards getting students to consider the internet as a large data source. If the conversation reaches a lull, just tell the class â€œThe Internetâ€.<br /><br />ğŸ™ï¸ <strong>Say:</strong> The models weâ€™ve started to make today are a great start and represent a good starting collection of words, but canâ€™t possibly encompass all of the data weâ€™d need to represent the entire world and all of its complexity. To solve this, most modern large language models are trained on huge collections of information usually from the internet, such as the entirety of wikipedia. By using such large quantities of data, large-language models are able to build up huge libraries of words they recognize and represent natural language.<br /><br />Teaching Tip: Looking Inside the Box<br />The article â€œInside the secret list of websites that make AI like ChatGPT sound smartâ€ from the Washington Post has a detailed list of how the internet and various websites have been used to train current large-language models. We donâ€™t recommend using this article for classroom use as aspects may not be appropriate, but the interactive web version of the article (link here) includes an interactive component where you can type in the name of a website and see if itâ€™s been used to train large language models (if the website is behind a paywall, consider investigating if your local library allows limited free access). This can be a useful illustration of just how much data was used to train large-language models.<br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_19.png"></td><td><br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_20.png"></td><td>[Still todo: make the graphic organizer]<br /></td></tr><tr><td><img src="https://jamjamgobambam.github.io/curriculum-drafts/slide-images/computer-vision/136LHOlg7SIL0UZ0SrcEkxZhs0kE-UNWw1D_frEPLkdE/slide_21.png"></td><td><br /></td></tr></table></body></html>